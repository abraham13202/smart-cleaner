"""
Comprehensive Word document report generator for data cleaning pipeline.
Generates professional reports with all steps, visualizations, and results.
"""

from typing import Dict, List, Any, Optional
import pandas as pd
from datetime import datetime
import os

try:
    from docx import Document
    from docx.shared import Inches, Pt, RGBColor
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    from docx.oxml.ns import qn
    from docx.oxml import OxmlElement
except ImportError:
    Document = None


class ReportGenerator:
    """
    Generate comprehensive Word document reports for data cleaning pipelines.
    """

    def __init__(self, output_file: str = "data_cleaning_report.docx"):
        """
        Initialize report generator.

        Args:
            output_file: Output filename for the Word document
        """
        if Document is None:
            raise ImportError(
                "python-docx not installed. "
                "Install with: pip install python-docx"
            )

        self.output_file = output_file
        self.doc = Document()
        self._setup_styles()

    def _setup_styles(self):
        """Set up document styles."""
        # Set default font
        style = self.doc.styles['Normal']
        font = style.font
        font.name = 'Calibri'
        font.size = Pt(11)

    def generate_report(
        self,
        original_df: pd.DataFrame,
        cleaned_df: pd.DataFrame,
        pipeline_report: Dict[str, Any],
        visualization_dir: Optional[str] = None,
    ) -> str:
        """
        Generate comprehensive data cleaning report.

        Args:
            original_df: Original DataFrame before cleaning
            cleaned_df: Cleaned DataFrame after processing
            pipeline_report: Report from AutoPreprocessor
            visualization_dir: Directory with visualization images

        Returns:
            Path to generated report
        """
        # Title page
        self._add_title_page()

        # Executive summary
        self._add_executive_summary(original_df, cleaned_df, pipeline_report)

        # Data profile (before)
        self._add_data_profile(original_df, "Original Data Profile")

        # Processing steps
        self._add_processing_steps(pipeline_report)

        # Data profile (after)
        self._add_data_profile(cleaned_df, "Cleaned Data Profile")

        # Visualizations
        if visualization_dir and os.path.exists(visualization_dir):
            self._add_visualizations(visualization_dir)

        # Detailed results
        self._add_detailed_results(original_df, cleaned_df, pipeline_report)

        # Recommendations
        self._add_recommendations(pipeline_report)

        # Save document
        self.doc.save(self.output_file)
        return self.output_file

    def _add_title_page(self):
        """Add title page."""
        # Title
        title = self.doc.add_heading('Data Cleaning Report', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER

        # Subtitle
        subtitle = self.doc.add_paragraph()
        subtitle.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = subtitle.add_run('Comprehensive Data Preprocessing Analysis')
        run.font.size = Pt(16)
        run.font.color.rgb = RGBColor(70, 70, 70)

        self.doc.add_paragraph()
        self.doc.add_paragraph()

        # Generated info
        info = self.doc.add_paragraph()
        info.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = info.add_run(f'Generated: {datetime.now().strftime("%B %d, %Y at %I:%M %p")}')
        run.font.size = Pt(12)
        run.font.color.rgb = RGBColor(100, 100, 100)

        # Generated by
        gen_by = self.doc.add_paragraph()
        gen_by.alignment = WD_ALIGN_PARAGRAPH.CENTER
        run = gen_by.add_run('Generated by Smart Cleaner AI')
        run.font.size = Pt(10)
        run.font.italic = True

        self.doc.add_page_break()

    def _add_executive_summary(self, original_df, cleaned_df, report):
        """Add executive summary."""
        self.doc.add_heading('Executive Summary', 1)

        summary_data = [
            ('Original Dataset Size', f"{original_df.shape[0]:,} rows × {original_df.shape[1]} columns"),
            ('Final Dataset Size', f"{cleaned_df.shape[0]:,} rows × {cleaned_df.shape[1]} columns"),
            ('Rows Removed', f"{report.get('rows_removed', 0):,}"),
            ('Original Missing Values', f"{original_df.isnull().sum().sum():,}"),
            ('Final Missing Values', f"{cleaned_df.isnull().sum().sum():,}"),
        ]

        for label, value in summary_data:
            p = self.doc.add_paragraph()
            p.add_run(f"{label}: ").bold = True
            p.add_run(value)

        # Quality improvement
        quality = report.get('data_quality_improvement', {})
        if quality:
            self.doc.add_paragraph()
            self.doc.add_paragraph('Data Quality Metrics:', style='Heading 2')

            p = self.doc.add_paragraph()
            p.add_run('Completeness Before: ').bold = True
            p.add_run(f"{quality.get('completeness_before', 0):.2f}%")

            p = self.doc.add_paragraph()
            p.add_run('Completeness After: ').bold = True
            p.add_run(f"{quality.get('completeness_after', 0):.2f}%")

            p = self.doc.add_paragraph()
            p.add_run('Improvement: ').bold = True
            improvement = quality.get('completeness_improvement', 0)
            p.add_run(f"+{improvement:.2f}%" if improvement > 0 else f"{improvement:.2f}%")

        self.doc.add_page_break()

    def _add_data_profile(self, df, title):
        """Add data profile section."""
        self.doc.add_heading(title, 1)

        # Basic stats
        self.doc.add_paragraph('Dataset Overview:', style='Heading 2')

        stats = [
            ('Shape', f"{df.shape[0]:,} rows × {df.shape[1]} columns"),
            ('Memory Usage', f"{df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB"),
            ('Duplicate Rows', f"{df.duplicated().sum():,}"),
            ('Total Missing Values', f"{df.isnull().sum().sum():,}"),
        ]

        for label, value in stats:
            p = self.doc.add_paragraph(style='List Bullet')
            p.add_run(f"{label}: ").bold = True
            p.add_run(value)

        # Column details
        self.doc.add_paragraph()
        self.doc.add_paragraph('Columns with Missing Values:', style='Heading 2')

        missing = df.isnull().sum()
        missing = missing[missing > 0].sort_values(ascending=False)

        if len(missing) == 0:
            self.doc.add_paragraph('✓ No missing values!', style='List Bullet')
        else:
            for col, count in missing.items():
                pct = (count / len(df)) * 100
                p = self.doc.add_paragraph(style='List Bullet')
                p.add_run(f"{col}: ").bold = True
                p.add_run(f"{count:,} ({pct:.1f}%)")

        self.doc.add_page_break()

    def _add_processing_steps(self, report):
        """Add processing steps section."""
        self.doc.add_heading('Data Processing Steps', 1)

        steps = report.get('steps', [])

        for i, step in enumerate(steps, 1):
            step_name = step.get('name', 'Unknown Step').replace('_', ' ').title()
            status = step.get('status', 'unknown')

            # Step heading
            heading = self.doc.add_heading(f"Step {i}: {step_name}", 2)

            # Status
            p = self.doc.add_paragraph()
            p.add_run('Status: ').bold = True
            status_text = "✓ Completed" if status == "completed" else "○ Skipped"
            run = p.add_run(status_text)
            if status == "completed":
                run.font.color.rgb = RGBColor(0, 128, 0)

            # Details
            step_report = step.get('report', {})

            if step_name == 'Remove Duplicates':
                if 'duplicate_count' in step_report:
                    p = self.doc.add_paragraph(style='List Bullet')
                    p.add_run(f"Duplicates found: {step_report['duplicate_count']:,}")

                    p = self.doc.add_paragraph(style='List Bullet')
                    p.add_run(f"Rows removed: {step_report.get('rows_removed', 0):,}")

            elif step_name == 'Validate Health':
                validations = step_report.get('validations', [])
                if validations:
                    for val in validations:
                        if 'invalid_count' in val:
                            p = self.doc.add_paragraph(style='List Bullet 2')
                            p.add_run(f"{val['column']}: ").bold = True
                            p.add_run(f"{val['invalid_count']:,} invalid values fixed")

            elif step_name == 'Handle Outliers':
                outliers = step_report.get('outliers', [])
                if outliers:
                    for outlier in outliers[:10]:  # Show top 10
                        if 'outliers_detected' in outlier:
                            p = self.doc.add_paragraph(style='List Bullet 2')
                            p.add_run(f"{outlier['column']}: ").bold = True
                            p.add_run(f"{outlier['outliers_detected']:,} outliers ({outlier['percentage']:.1f}%)")

            elif step_name == 'Impute Missing':
                imputations = step_report.get('imputations', [])
                if imputations:
                    self.doc.add_paragraph('Imputation strategies applied:', style='List Bullet')
                    for imp in imputations:
                        p = self.doc.add_paragraph(style='List Bullet 2')
                        p.add_run(f"{imp['column']}: ").bold = True
                        p.add_run(f"{imp['strategy']}")

                        if imp.get('reasoning'):
                            p = self.doc.add_paragraph(style='List Bullet 3')
                            run = p.add_run(f"Reasoning: {imp['reasoning'][:150]}...")
                            run.font.size = Pt(9)
                            run.font.italic = True

        self.doc.add_page_break()

    def _add_visualizations(self, viz_dir):
        """Add visualizations section."""
        self.doc.add_heading('Data Visualizations', 1)

        # Find all PNG files in visualization directory
        viz_files = []
        if os.path.exists(viz_dir):
            viz_files = [f for f in os.listdir(viz_dir) if f.endswith('.png')]

        if not viz_files:
            self.doc.add_paragraph('No visualizations available.')
            return

        for viz_file in sorted(viz_files):
            viz_path = os.path.join(viz_dir, viz_file)

            # Add visualization title
            title = viz_file.replace('.png', '').replace('_', ' ').title()
            self.doc.add_heading(title, 2)

            # Add image
            try:
                self.doc.add_picture(viz_path, width=Inches(6))
                last_paragraph = self.doc.paragraphs[-1]
                last_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
            except Exception as e:
                self.doc.add_paragraph(f"Error loading image: {e}")

            self.doc.add_paragraph()

        self.doc.add_page_break()

    def _add_detailed_results(self, original_df, cleaned_df, report):
        """Add detailed results section."""
        self.doc.add_heading('Detailed Results', 1)

        # Column-by-column comparison
        self.doc.add_paragraph('Column-by-Column Analysis:', style='Heading 2')

        for col in original_df.columns:
            self.doc.add_heading(col, 3)

            # Before stats
            orig_missing = original_df[col].isnull().sum()
            clean_missing = cleaned_df[col].isnull().sum()

            p = self.doc.add_paragraph(style='List Bullet')
            p.add_run('Missing values: ').bold = True
            p.add_run(f"{orig_missing:,} → {clean_missing:,}")

            # If numeric, show stats
            if pd.api.types.is_numeric_dtype(original_df[col]):
                orig_mean = original_df[col].mean()
                clean_mean = cleaned_df[col].mean()

                p = self.doc.add_paragraph(style='List Bullet')
                p.add_run('Mean: ').bold = True
                p.add_run(f"{orig_mean:.2f} → {clean_mean:.2f}")

        self.doc.add_page_break()

    def _add_recommendations(self, report):
        """Add recommendations section."""
        self.doc.add_heading('Next Steps & Recommendations', 1)

        recommendations = [
            "✓ Your data has been cleaned and is ready for machine learning",
            "✓ Review the imputation strategies applied to ensure they align with your domain knowledge",
            "✓ Check the visualizations for any unexpected patterns",
            "✓ Consider feature engineering based on the cleaned data",
            "✓ Split data into train/test sets before modeling",
        ]

        for rec in recommendations:
            self.doc.add_paragraph(rec, style='List Bullet')

        self.doc.add_paragraph()
        self.doc.add_paragraph('Data Quality Summary:', style='Heading 2')

        quality = report.get('data_quality_improvement', {})
        final_quality = quality.get('completeness_after', 0)

        if final_quality >= 95:
            level = "Excellent"
            color = RGBColor(0, 128, 0)
        elif final_quality >= 85:
            level = "Good"
            color = RGBColor(0, 100, 0)
        elif final_quality >= 70:
            level = "Fair"
            color = RGBColor(200, 100, 0)
        else:
            level = "Needs Improvement"
            color = RGBColor(200, 0, 0)

        p = self.doc.add_paragraph()
        p.add_run('Overall Data Quality: ').bold = True
        run = p.add_run(f"{level} ({final_quality:.1f}% complete)")
        run.font.color.rgb = color
